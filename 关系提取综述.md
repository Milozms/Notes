# 关系提取综述

整理与翻译：张茂森

## 摘要
本文内容整理并翻译自Nguyen Bach与Sameer Badaskar所写的A Review of Relation Extraction一文，与Shantanu Kumar所写的A Survey of Deep Learning Methods for Relation Extraction一文。

## 导论
关系提取是指从无结构文本中提取实体之间的关系，从而将其转化为结构化信息的过程。关系定义在实体的元组$ t = (e_1, e_2, ..., e_n) $ 之上。大多数关系提取系统着重于提取二元关系，例如*坐落于（卡耐基梅隆大学，匹兹堡）*，*父亲（Manuel Blum, Avrim Blum）*。高阶关系与之类似。

我们将讨论有监督方法，将关系提取问题公式化为二分类问题。之后我们将讨论基于特征的监督方法(Kambhatla, 2004)(Zhao & Grishman, 2005)和基于核的监督方法。核方法的优点是能够高效地在多项式时间内搜索足够大的特征空间（通常是指数级的，在某些例子中是无穷的），并且不需要显式地表示特征。我们将讨论并对比树形核、子序列核和依存树核。

近期，半监督方法和bootstrapping方法引起了注意，例如DIPRE(Brin, 1998)和Snowball(Agichtein & Gravano, 2000)，这类方法只需要少量的人工标记的种子实例或少量的人工提取模式来启动训练，使用了类似于Yarowsky的词语消歧义算法的半监督方法；另外KnowItAll(Etzioni, 2005)和TextRunner(Banko, 2007)提出了使用自训练关系二分类器的大规模关系提取系统。

## 有监督方法
出于简便，我们仅讨论两个实体之间的二元关系。多元关系在之后讨论。给定一个句子$S = w_1, w_2, ..., e_1, ..., w_j, ..., e_2, ..., w_n$，其中$e_1, e_2$是实体，我们给出一个映射函数$f$：

$$
f_R(T(S)) = 
\left\{  
             \begin{array}{lr}  
             +1, & If\ e_1\ and\ e_2\ are\ related\ according\ to\ relation\ R \\
             -1, & otherwise   
             \end{array}  
\right.  
$$

其中$T(S)$是从S中提取的特征。映射函数$f$决定了句子中的实体之间是否存在一个关系。换言之，实体关系提取这一任务变成了实体关系“识别”。如果标记的正样例和负样例数据可以用来训练，则函数$f$可以被构建成一个判别分类器（例如感知器、支持向量机等），经过预处理（词性标注、依存分析）之后用文本级特征来训练。从另一角度来说，分类器的输入也可以是结构化表示，如解析树。由于分类器训练的输入的不同，监督方法也可以分为基于特征的方法和核方法。

### 基于特征的方法
从文本中提取的句法和语义的特征，可以作为判定句子中的实体是否有某种关系的线索。句法特征包括：实体本身，实体类别，实体之间的词序列，实体之间的词的数量，解析树中实体之间的路径。语义特征包括：依存分析树中实体之间的路径。这些特征都可以在特征向量中表示并输入到分类器中。

自然语言处理的应用往往涉及输入数据的结构化表示，因此仅使用相关特征的子集很难达到最优。作为补充，人们设计了专用于关系提取的核，用于更充分地利用输入数据的表示。

### 核方法
关系提取的核方法基于字符串核（string-kernels），这一方法源于文本分类。给出字符串x和y，字符串核基于它们的公共子串数量计算它们的相似度。每个字符串被映射到高维空间中的向量，每个维度对应一个特定的子串是否出现。例如字符串cat可做如下表示：

$$
\phi(x=cat) = [\phi_a(x)\ ..\ \phi_c(x)\ ..\ \phi_t(x)\ ..\ \phi_{at}(x)\ ..\ \phi_{ca}(x)\ ..\ \phi_{ct}(x)\ ..\ \phi_{cat}(x)] 
$$
其中

$$
\phi_a(x)=\phi_c(x)=\phi_t(x) = \lambda \\
\phi_{at}(x)=\phi_{ca}(x)=\phi_{ct}(x) = \lambda^2\\
\phi_{cat}(x) = \lambda^3
$$
$\lambda$被称为衰减因子，用于惩罚较长的、不相邻的子序列。事实上$\phi_{ct}(cat)$应该比$\phi_{at}(cat)$和$\phi_{ca}(cat)$受到更多惩罚（$\lambda^3$），因为不相邻。对于索引为$i = i_1, i_2, ..., i_{|u|}$的子串$u$，令$u$的长度为$l(i)=i_{|u|}-i_1+1$，$u$在字符串x的高维空间中对应的坐标值为

$$
\phi_u(x) = \sum_{i:u=x[i]} \lambda^{l(i)}
$$
（我的理解：这里的求和的意思是，如果子序列u在x中出现多次，则把多次的衰减因子相加。上述例子中ct的衰减因子应为3次方。）

若U是字符串x和y包括的所有可能的子串，则x和y的核相似度为
$$
K(x,y)=\phi(x)^T \phi(y) = \sum_{u \in U}\phi_u(x)^T \phi_u(y)
$$
这一相似度的计算可以使用动态规划，复杂度为$O(|x|||y|^2)$。

上述公式更泛化的解释是：如果x和y是两个对象，$K(x,y)$计算的是他们之间结构的共同点，从而计算他们的相似度。在关系提取中，如果$x^+$和$x^-$分别表示训练数据中的正样例和负样例，而y表示测试样例，则$K(x^+,y)>K(x^-,y)$意味着y包含一个关系（y更接近正样例）。实际上$K(x,y)$就是支持向量机和感知机中使用的相似性函数。在关系提取中，$x^+$、$x^-$和y可以用实体之间的词序列和包含实体的解析树表示。

#### 特征包核(Bag of features)
以句子"*The headquarters of* **Google** *are situated in* **Mountain View**"为例。已知Google和Mountain View是实体，词situated和headquarters表明*机构-位置*关系，则我们可以得出：实体的上下文可以用来判定它们之间是否有关系。句子s中包含实体$e_1$和$e_2$，可以被表示为$s = sb\ e_1\ sm\ e_2\ sa$，其中sb、sm、sa分别表示在实体之前、之间、之后的上下文词。给定测试样例句子t，t包含实体实体$e'_1$和$e'_2$，使用子序列和计算两个句子的三组上下文之间的相似度（这里使用词语级序列，而不是字符级序列），得到三个子核，三个子核结合就得到了最终的核。用子序列核结合支持向量机，显著提高了关系提取的准确率。

#### 树形核

与之前的方法相比，树形核用句子的结构化浅解析树（shallow parsing tree）


